{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cce8b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === ResNet101 ===\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === DATASET SETUP ===\n",
    "data_dir = 'C:/Users/ayesh/Downloads/combined_dataset'\n",
    "metadata_path = 'C:/Users/ayesh/Downloads/scin_dataset/dataset/modified_metadata.csv'\n",
    "class_names = ['malignant', 'benign']\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "labels = [label for _, label in dataset.samples]\n",
    "\n",
    "# Stratified splitting\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_val_idx, test_idx in splitter.split(dataset.samples, labels):\n",
    "    pass\n",
    "\n",
    "train_val_labels = [labels[i] for i in train_val_idx]\n",
    "splitter_val = StratifiedShuffleSplit(n_splits=1, test_size=0.125, random_state=42)\n",
    "for train_idx, val_idx in splitter_val.split([dataset.samples[i] for i in train_val_idx], train_val_labels):\n",
    "    pass\n",
    "\n",
    "train_indices = [train_val_idx[i] for i in train_idx]\n",
    "val_indices = [train_val_idx[i] for i in val_idx]\n",
    "test_indices = test_idx\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# === MODEL SETUP ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet101(pretrained=True)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(model.fc.in_features, 2)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# === TRAINING ===\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct / total\n",
    "    val_loss /= total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= 3:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# === TEST SET EVALUATION ===\n",
    "model.eval()\n",
    "test_preds, test_labels, test_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "print(\"\\n=== TEST SET METRICS ===\")\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))\n",
    "print(\"F1 Score:\", f1_score(test_labels, test_preds))\n",
    "print(\"Precision:\", precision_score(test_labels, test_preds))\n",
    "print(\"Recall:\", recall_score(test_labels, test_preds))\n",
    "if len(set(test_labels)) > 1:\n",
    "    auc_score = roc_auc_score(test_labels, test_probs)\n",
    "    print(\"AUC:\", auc_score)\n",
    "\n",
    "# === CONFUSION MATRIX ===\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "# === SKIN TONE ANALYSIS ON TEST SET ===\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "test_paths = [dataset.samples[i][0] for i in test_indices]\n",
    "test_filenames = [os.path.basename(p) for p in test_paths]\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"filename\": test_filenames,\n",
    "    \"true_label\": test_labels,\n",
    "    \"predicted_label\": test_preds\n",
    "})\n",
    "\n",
    "metadata['filename'] = metadata['filename'].str.strip()\n",
    "results['filename'] = results['filename'].str.strip()\n",
    "merged_df = results.merge(metadata, on=\"filename\")\n",
    "\n",
    "# Accuracy by skin tone\n",
    "total_by_tone = merged_df['fitzpatrick_skin_type'].value_counts()\n",
    "correct_by_tone = merged_df[merged_df.true_label == merged_df.predicted_label]['fitzpatrick_skin_type'].value_counts()\n",
    "accuracy_by_tone = (correct_by_tone / total_by_tone * 100).round(2)\n",
    "\n",
    "# Misclassification counts and percentages\n",
    "misclassified = merged_df[merged_df.true_label != merged_df.predicted_label]\n",
    "miscounts = misclassified['fitzpatrick_skin_type'].value_counts()\n",
    "percent_misclassified = (miscounts / total_by_tone * 100).round(2)\n",
    "\n",
    "print(\"\\nMisclassification counts by skin tone (Test Set):\")\n",
    "print(miscounts)\n",
    "print(\"\\nMisclassification percentages by skin tone (Test Set):\")\n",
    "print(percent_misclassified)\n",
    "print(\"\\nAccuracy by skin tone (Test Set):\")\n",
    "print(accuracy_by_tone)\n",
    "\n",
    "# Plot accuracy\n",
    "sns.barplot(x=accuracy_by_tone.index, y=accuracy_by_tone.values)\n",
    "plt.title(\"Test Set Accuracy by Fitzpatrick Skin Tone\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Skin Tone\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d94073",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === ResNet50 ===\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === DATASET SETUP ===\n",
    "data_dir = 'C:/Users/ayesh/Downloads/combined_dataset'\n",
    "metadata_path = 'C:/Users/ayesh/Downloads/scin_dataset/dataset/modified_metadata.csv'\n",
    "class_names = ['malignant', 'benign']\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "labels = [label for _, label in dataset.samples]\n",
    "\n",
    "# Stratified splitting\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_val_idx, test_idx in splitter.split(dataset.samples, labels):\n",
    "    pass\n",
    "\n",
    "train_val_labels = [labels[i] for i in train_val_idx]\n",
    "splitter_val = StratifiedShuffleSplit(n_splits=1, test_size=0.125, random_state=42)\n",
    "for train_idx, val_idx in splitter_val.split([dataset.samples[i] for i in train_val_idx], train_val_labels):\n",
    "    pass\n",
    "\n",
    "train_indices = [train_val_idx[i] for i in train_idx]\n",
    "val_indices = [train_val_idx[i] for i in val_idx]\n",
    "test_indices = test_idx\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# === MODEL SETUP ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(model.fc.in_features, 2)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# === TRAINING ===\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct / total\n",
    "    val_loss /= total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= 3:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# === TEST SET EVALUATION ===\n",
    "model.eval()\n",
    "test_preds, test_labels, test_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "print(\"\\n=== TEST SET METRICS ===\")\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))\n",
    "print(\"F1 Score:\", f1_score(test_labels, test_preds))\n",
    "print(\"Precision:\", precision_score(test_labels, test_preds))\n",
    "print(\"Recall:\", recall_score(test_labels, test_preds))\n",
    "if len(set(test_labels)) > 1:\n",
    "    auc_score = roc_auc_score(test_labels, test_probs)\n",
    "    print(\"AUC:\", auc_score)\n",
    "\n",
    "# === CONFUSION MATRIX ===\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "# === SKIN TONE ANALYSIS ON TEST SET ===\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "test_paths = [dataset.samples[i][0] for i in test_indices]\n",
    "test_filenames = [os.path.basename(p) for p in test_paths]\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"filename\": test_filenames,\n",
    "    \"true_label\": test_labels,\n",
    "    \"predicted_label\": test_preds\n",
    "})\n",
    "\n",
    "metadata['filename'] = metadata['filename'].str.strip()\n",
    "results['filename'] = results['filename'].str.strip()\n",
    "merged_df = results.merge(metadata, on=\"filename\")\n",
    "\n",
    "# Accuracy by skin tone\n",
    "total_by_tone = merged_df['fitzpatrick_skin_type'].value_counts()\n",
    "correct_by_tone = merged_df[merged_df.true_label == merged_df.predicted_label]['fitzpatrick_skin_type'].value_counts()\n",
    "accuracy_by_tone = (correct_by_tone / total_by_tone * 100).round(2)\n",
    "\n",
    "# Misclassification counts and percentages\n",
    "misclassified = merged_df[merged_df.true_label != merged_df.predicted_label]\n",
    "miscounts = misclassified['fitzpatrick_skin_type'].value_counts()\n",
    "percent_misclassified = (miscounts / total_by_tone * 100).round(2)\n",
    "\n",
    "print(\"\\nMisclassification counts by skin tone (Test Set):\")\n",
    "print(miscounts)\n",
    "print(\"\\nMisclassification percentages by skin tone (Test Set):\")\n",
    "print(percent_misclassified)\n",
    "print(\"\\nAccuracy by skin tone (Test Set):\")\n",
    "print(accuracy_by_tone)\n",
    "\n",
    "# Plot accuracy\n",
    "sns.barplot(x=accuracy_by_tone.index, y=accuracy_by_tone.values)\n",
    "plt.title(\"Test Set Accuracy by Fitzpatrick Skin Tone\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Skin Tone\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b3abf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === ResNet18 ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === DATASET SETUP ===\n",
    "data_dir = 'C:/Users/ayesh/Downloads/combined_dataset'\n",
    "metadata_path = 'C:/Users/ayesh/Downloads/scin_dataset/dataset/modified_metadata.csv'\n",
    "class_names = ['malignant', 'benign']\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "labels = [label for _, label in dataset.samples]\n",
    "\n",
    "# Stratified splitting\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_val_idx, test_idx in splitter.split(dataset.samples, labels):\n",
    "    pass\n",
    "\n",
    "train_val_labels = [labels[i] for i in train_val_idx]\n",
    "splitter_val = StratifiedShuffleSplit(n_splits=1, test_size=0.125, random_state=42)\n",
    "for train_idx, val_idx in splitter_val.split([dataset.samples[i] for i in train_val_idx], train_val_labels):\n",
    "    pass\n",
    "\n",
    "train_indices = [train_val_idx[i] for i in train_idx]\n",
    "val_indices = [train_val_idx[i] for i in val_idx]\n",
    "test_indices = test_idx\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# === MODEL SETUP ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(model.fc.in_features, 2)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# === TRAINING ===\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0.0, 0, 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct / total\n",
    "    val_loss /= total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= 3:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# === TEST SET EVALUATION ===\n",
    "model.eval()\n",
    "test_preds, test_labels, test_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "print(\"\\n=== TEST SET METRICS ===\")\n",
    "print(\"Classification Report:\\n\", classification_report(test_labels, test_preds))\n",
    "print(\"F1 Score:\", f1_score(test_labels, test_preds))\n",
    "print(\"Precision:\", precision_score(test_labels, test_preds))\n",
    "print(\"Recall:\", recall_score(test_labels, test_preds))\n",
    "if len(set(test_labels)) > 1:\n",
    "    auc_score = roc_auc_score(test_labels, test_probs)\n",
    "    print(\"AUC:\", auc_score)\n",
    "\n",
    "# === CONFUSION MATRIX ===\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "# === SKIN TONE ANALYSIS ON TEST SET ===\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "test_paths = [dataset.samples[i][0] for i in test_indices]\n",
    "test_filenames = [os.path.basename(p) for p in test_paths]\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"filename\": test_filenames,\n",
    "    \"true_label\": test_labels,\n",
    "    \"predicted_label\": test_preds\n",
    "})\n",
    "\n",
    "metadata['filename'] = metadata['filename'].str.strip()\n",
    "results['filename'] = results['filename'].str.strip()\n",
    "merged_df = results.merge(metadata, on=\"filename\")\n",
    "\n",
    "# Accuracy by skin tone\n",
    "total_by_tone = merged_df['fitzpatrick_skin_type'].value_counts()\n",
    "correct_by_tone = merged_df[merged_df.true_label == merged_df.predicted_label]['fitzpatrick_skin_type'].value_counts()\n",
    "accuracy_by_tone = (correct_by_tone / total_by_tone * 100).round(2)\n",
    "\n",
    "# Misclassification counts and percentages\n",
    "misclassified = merged_df[merged_df.true_label != merged_df.predicted_label]\n",
    "miscounts = misclassified['fitzpatrick_skin_type'].value_counts()\n",
    "percent_misclassified = (miscounts / total_by_tone * 100).round(2)\n",
    "\n",
    "print(\"\\nMisclassification counts by skin tone (Test Set):\")\n",
    "print(miscounts)\n",
    "print(\"\\nMisclassification percentages by skin tone (Test Set):\")\n",
    "print(percent_misclassified)\n",
    "print(\"\\nAccuracy by skin tone (Test Set):\")\n",
    "print(accuracy_by_tone)\n",
    "\n",
    "# Plot accuracy\n",
    "sns.barplot(x=accuracy_by_tone.index, y=accuracy_by_tone.values)\n",
    "plt.title(\"Test Set Accuracy by Fitzpatrick Skin Tone\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Skin Tone\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
